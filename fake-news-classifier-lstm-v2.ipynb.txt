{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-10T12:39:18.388262Z","iopub.execute_input":"2022-01-10T12:39:18.389314Z","iopub.status.idle":"2022-01-10T12:39:18.433478Z","shell.execute_reply.started":"2022-01-10T12:39:18.389118Z","shell.execute_reply":"2022-01-10T12:39:18.432748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Following cell will import necessary packages:**\n\n* Embedding is to convert words into vectors with embedding layers (works on top of one_hot)\n* One_hot is to convert words into index (numbers) location of the words in a dictionary (given vocab size)\n* Pad_Sequences is to impute 0's pre/post sentences to complete the max sentence length\n\n\n--------------------------\n\n* Vocabulary size - Basically a dictionary of words within which the words would be converted to vectors and their position would be noted","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import one_hot\n#-----------------------------------------------------------------\n\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:22.852365Z","iopub.execute_input":"2022-01-07T04:34:22.852671Z","iopub.status.idle":"2022-01-07T04:34:30.256641Z","shell.execute_reply.started":"2022-01-07T04:34:22.852628Z","shell.execute_reply":"2022-01-07T04:34:30.255615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking tensorflow version\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:30.25818Z","iopub.execute_input":"2022-01-07T04:34:30.258531Z","iopub.status.idle":"2022-01-07T04:34:30.266671Z","shell.execute_reply.started":"2022-01-07T04:34:30.258488Z","shell.execute_reply":"2022-01-07T04:34:30.265965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing data\ndf_fake = pd.read_csv('../input/fake-and-real-news-dataset/Fake.csv')\ndf_real = pd.read_csv('../input/fake-and-real-news-dataset/True.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:30.270388Z","iopub.execute_input":"2022-01-07T04:34:30.271094Z","iopub.status.idle":"2022-01-07T04:34:33.330916Z","shell.execute_reply.started":"2022-01-07T04:34:30.271056Z","shell.execute_reply":"2022-01-07T04:34:33.329997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_fake.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.332272Z","iopub.execute_input":"2022-01-07T04:34:33.332659Z","iopub.status.idle":"2022-01-07T04:34:33.351102Z","shell.execute_reply.started":"2022-01-07T04:34:33.332614Z","shell.execute_reply":"2022-01-07T04:34:33.350298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_real.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.352218Z","iopub.execute_input":"2022-01-07T04:34:33.352548Z","iopub.status.idle":"2022-01-07T04:34:33.364054Z","shell.execute_reply.started":"2022-01-07T04:34:33.352518Z","shell.execute_reply":"2022-01-07T04:34:33.362994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_fake['label'] = 1\ndf_real['label'] = 0","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.365474Z","iopub.execute_input":"2022-01-07T04:34:33.365791Z","iopub.status.idle":"2022-01-07T04:34:33.3786Z","shell.execute_reply.started":"2022-01-07T04:34:33.365758Z","shell.execute_reply":"2022-01-07T04:34:33.37751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Unioning both the datasets\ndf = pd.concat([df_fake, df_real])\ndf.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.380242Z","iopub.execute_input":"2022-01-07T04:34:33.380754Z","iopub.status.idle":"2022-01-07T04:34:33.397524Z","shell.execute_reply.started":"2022-01-07T04:34:33.380717Z","shell.execute_reply":"2022-01-07T04:34:33.396532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.398747Z","iopub.execute_input":"2022-01-07T04:34:33.398999Z","iopub.status.idle":"2022-01-07T04:34:33.412969Z","shell.execute_reply.started":"2022-01-07T04:34:33.398971Z","shell.execute_reply":"2022-01-07T04:34:33.411891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of records in Fake: \", df_fake.shape[0], \n      \"\\nNumber of records in Real: \", df_real.shape[0], \n      \"\\nNumber of records in final df: \", df.shape[0])\nprint(\"QC: \", df_fake.shape[0]+df_real.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.416294Z","iopub.execute_input":"2022-01-07T04:34:33.4168Z","iopub.status.idle":"2022-01-07T04:34:33.426068Z","shell.execute_reply.started":"2022-01-07T04:34:33.4167Z","shell.execute_reply":"2022-01-07T04:34:33.425056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the unique values\n\ndf.label.unique()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.427469Z","iopub.execute_input":"2022-01-07T04:34:33.428107Z","iopub.status.idle":"2022-01-07T04:34:33.441264Z","shell.execute_reply.started":"2022-01-07T04:34:33.428064Z","shell.execute_reply":"2022-01-07T04:34:33.44037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking for NULL values\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.442624Z","iopub.execute_input":"2022-01-07T04:34:33.442848Z","iopub.status.idle":"2022-01-07T04:34:33.469031Z","shell.execute_reply.started":"2022-01-07T04:34:33.442812Z","shell.execute_reply":"2022-01-07T04:34:33.468147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting independent and dependent features\n\nX=df.drop('label',axis=1)\nY=df['label']","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.470343Z","iopub.execute_input":"2022-01-07T04:34:33.471168Z","iopub.status.idle":"2022-01-07T04:34:33.482402Z","shell.execute_reply.started":"2022-01-07T04:34:33.471134Z","shell.execute_reply":"2022-01-07T04:34:33.481376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(Y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.483775Z","iopub.execute_input":"2022-01-07T04:34:33.484093Z","iopub.status.idle":"2022-01-07T04:34:33.492119Z","shell.execute_reply.started":"2022-01-07T04:34:33.484056Z","shell.execute_reply":"2022-01-07T04:34:33.491284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining vocab size\n\nvoc_size=5000","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.493307Z","iopub.execute_input":"2022-01-07T04:34:33.49407Z","iopub.status.idle":"2022-01-07T04:34:33.501847Z","shell.execute_reply.started":"2022-01-07T04:34:33.494025Z","shell.execute_reply":"2022-01-07T04:34:33.500998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Taking a copy of independent features\nmsg=X.copy()\nmsg.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.502964Z","iopub.execute_input":"2022-01-07T04:34:33.503196Z","iopub.status.idle":"2022-01-07T04:34:33.522699Z","shell.execute_reply.started":"2022-01-07T04:34:33.503172Z","shell.execute_reply":"2022-01-07T04:34:33.521881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msg.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.524096Z","iopub.execute_input":"2022-01-07T04:34:33.524383Z","iopub.status.idle":"2022-01-07T04:34:33.53523Z","shell.execute_reply.started":"2022-01-07T04:34:33.524345Z","shell.execute_reply":"2022-01-07T04:34:33.534622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ps=PorterStemmer()\ncorpus = []\n\nfor i in range (0, len(msg)):\n    #print(i)\n    review = re.sub('[^a-zA-Z]',' ', msg['title'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:34:33.536385Z","iopub.execute_input":"2022-01-07T04:34:33.536713Z","iopub.status.idle":"2022-01-07T04:35:56.215176Z","shell.execute_reply.started":"2022-01-07T04:34:33.536684Z","shell.execute_reply":"2022-01-07T04:35:56.214363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sample items in corpus\n#look at sentences how the stopwords have been removed, stemming and lemmetization has been done\nprint(\"Length of list CORPUS: \", len(corpus))\ncorpus[1:10]","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:35:56.216339Z","iopub.execute_input":"2022-01-07T04:35:56.216572Z","iopub.status.idle":"2022-01-07T04:35:56.22334Z","shell.execute_reply.started":"2022-01-07T04:35:56.216545Z","shell.execute_reply":"2022-01-07T04:35:56.222458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Look at how all words have been assigned the index from a standard dictionary of 5000 words (remember 5000 is what we declared, we can change)","metadata":{}},{"cell_type":"code","source":"#Now pre-processing stage 1 is completed\n#As next step, we have to convert words into vectors using embedding layer..\n#But for that, we need to do one hot representation\n\nonehot_repr=[one_hot(words, voc_size) for words in corpus]\nonehot_repr[1:10]","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:35:56.22472Z","iopub.execute_input":"2022-01-07T04:35:56.22518Z","iopub.status.idle":"2022-01-07T04:35:56.943298Z","shell.execute_reply.started":"2022-01-07T04:35:56.225135Z","shell.execute_reply":"2022-01-07T04:35:56.942431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Embedding Representation**\n\n* Now once all words are conv. to vectors, we have to use word embedding to get sense of these numbers (ex., king and queen are relatable, king and apple aren't)\n* But to do that, we must have equal number of words in each title (row)\n* WHAT!!! That's impossible right? Don't worry we have library to overcome this -- Pad_sequences","metadata":{}},{"cell_type":"code","source":"#finding max length of sentence -- 10\n\ncount = 0\ncnt_lst = []\nfor element in onehot_repr:\n    cnt_lst.append(len(element))\n\n#------------\ncnt_lst.sort()\ncnt_lst[-1]","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:35:56.944444Z","iopub.execute_input":"2022-01-07T04:35:56.944656Z","iopub.status.idle":"2022-01-07T04:35:56.963921Z","shell.execute_reply.started":"2022-01-07T04:35:56.944632Z","shell.execute_reply":"2022-01-07T04:35:56.963006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#declaring the max sentence legnth\n\nsent_length = cnt_lst[-1]\nembedded_docs = pad_sequences(onehot_repr, padding='pre', maxlen=sent_length)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:35:56.9658Z","iopub.execute_input":"2022-01-07T04:35:56.966107Z","iopub.status.idle":"2022-01-07T04:35:57.151918Z","shell.execute_reply.started":"2022-01-07T04:35:56.966068Z","shell.execute_reply":"2022-01-07T04:35:57.150968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notice the pad_sequences had added 0's before the word to fill in the gap","metadata":{}},{"cell_type":"code","source":"embedded_docs[1]","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:35:57.153448Z","iopub.execute_input":"2022-01-07T04:35:57.15368Z","iopub.status.idle":"2022-01-07T04:35:57.161951Z","shell.execute_reply.started":"2022-01-07T04:35:57.153654Z","shell.execute_reply":"2022-01-07T04:35:57.161002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating model\n# embedding_vector_features is number of features model should consider, we may set it to any number\nembedding_vector_features=60\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features, input_length=sent_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(1,activation = 'sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\nprint(model.summary())\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:35:57.163876Z","iopub.execute_input":"2022-01-07T04:35:57.164332Z","iopub.status.idle":"2022-01-07T04:35:57.575383Z","shell.execute_reply.started":"2022-01-07T04:35:57.16427Z","shell.execute_reply":"2022-01-07T04:35:57.574371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#assigning the inputs \nX_final = np.array(embedded_docs)\nY_final = np.array(Y)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:35:57.57679Z","iopub.execute_input":"2022-01-07T04:35:57.577094Z","iopub.status.idle":"2022-01-07T04:35:57.586686Z","shell.execute_reply.started":"2022-01-07T04:35:57.577054Z","shell.execute_reply":"2022-01-07T04:35:57.585723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_final.shape, Y_final.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:35:57.58815Z","iopub.execute_input":"2022-01-07T04:35:57.588988Z","iopub.status.idle":"2022-01-07T04:35:57.595218Z","shell.execute_reply.started":"2022-01-07T04:35:57.588932Z","shell.execute_reply":"2022-01-07T04:35:57.594294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X_final, Y_final, test_size=0.10, random_state=20)\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.10, random_state=20)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:35:57.596148Z","iopub.execute_input":"2022-01-07T04:35:57.596659Z","iopub.status.idle":"2022-01-07T04:35:57.625073Z","shell.execute_reply.started":"2022-01-07T04:35:57.596627Z","shell.execute_reply":"2022-01-07T04:35:57.624392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, Y_train.shape, X_test.shape, Y_test.shape, X_val.shape, Y_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:35:57.628942Z","iopub.execute_input":"2022-01-07T04:35:57.62938Z","iopub.status.idle":"2022-01-07T04:35:57.635122Z","shell.execute_reply.started":"2022-01-07T04:35:57.629333Z","shell.execute_reply":"2022-01-07T04:35:57.634496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model training","metadata":{}},{"cell_type":"code","source":"model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs = 1, batch_size = 100)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T05:30:15.909666Z","iopub.execute_input":"2022-01-07T05:30:15.910046Z","iopub.status.idle":"2022-01-07T05:30:35.338872Z","shell.execute_reply.started":"2022-01-07T05:30:15.91001Z","shell.execute_reply":"2022-01-07T05:30:35.338297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Descent (GD) \n* Gradient descent is an optimizer that finds right weights to update on neurons such that loss would reach the global minima\n* It passes entire data into the neural network(Front propagation) -> Calculate Loss -> Update the weight startiong from last (Back propagation)\n* Since it passes entire data at once, it takes huge memory in **CPU/GPU** i.e., it is computational expensive\n     *  Think of it like *by default batch_size = 1*\n     \n## Stochastic gradient descent (SGD)\n* Stochastic gradient descent kind of like an updated version of GD to overcome some of its limitations.\n* As we know, GD passess entire dataset at once, SGD was designed in such a way that it passes 1 record at a time\n* If dataset is of **36367 records**, then each row will be processed at a time\n* This simply means that it passes one record into the neural network(Front propagation) -> Calculate Loss -> Update the weight startiong from last (Back propagation).. Then second record, then third and so on.... \n* Guess what? - When one problem solved, it leads to another one!\n* It took down the drawback of computational expensiveness. But since one record is processed at a time, it becomes very very slow...\n     * Think of it like *by default batch_size = number of available records (36367)*\n* Mini-batch SGD to the rescue!!\n\n## Mini-batch Stochastic gradient descent (MB-SGD)\n* It uses a batch_size that determines how many records to be processed at a time.\n* So, it overcomes drawbacks in GD and SGD and hence preferredfor DLs\n* If batch_size is set to 2, then it will break the entire data *(36367 records)* into 2 pieces *(18184 records each)*\n* Batch_size = how many pieces of data to be divided\n* Batch_size = number of iterations per epoch\n* Mini batch SGD - No default, we have to specify the number of batches. \n\nNote that number of batch size is NOT eq to number of records.","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\ndf = pd.DataFrame(dict(\n        Optimizers='GD;SGD;MB-SGD'.split(';'),\n        CPU=[95,4,20],\n        Time=[4,95,10],\n        Disk_Free=[1,1,70]\n    ))","metadata":{"execution":{"iopub.status.busy":"2022-01-10T12:42:19.713217Z","iopub.execute_input":"2022-01-10T12:42:19.713822Z","iopub.status.idle":"2022-01-10T12:42:19.720905Z","shell.execute_reply.started":"2022-01-10T12:42:19.713792Z","shell.execute_reply":"2022-01-10T12:42:19.72021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n\nfor i, (idx, row) in enumerate(df.set_index('Optimizers').iterrows()):\n    ax = axes[i // 3, i % 3]\n    row = row[row.gt(row.sum() * .01)]\n    ax.pie(row, labels=row.index, startangle=30)\n    ax.set_title(idx)\n\nfig.subplots_adjust(wspace=.2)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T12:42:21.873107Z","iopub.execute_input":"2022-01-10T12:42:21.873888Z","iopub.status.idle":"2022-01-10T12:42:22.466809Z","shell.execute_reply.started":"2022-01-10T12:42:21.873834Z","shell.execute_reply":"2022-01-10T12:42:22.465947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performance metrics and Accuracy","metadata":{}},{"cell_type":"code","source":"#Y_pred = model.predict_classes(X_test) (older versions of TF)\n\npredict_x=model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T05:22:21.929231Z","iopub.execute_input":"2022-01-07T05:22:21.930016Z","iopub.status.idle":"2022-01-07T05:22:23.284502Z","shell.execute_reply.started":"2022-01-07T05:22:21.929961Z","shell.execute_reply":"2022-01-07T05:22:23.28359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_x[1:10]","metadata":{"execution":{"iopub.status.busy":"2022-01-07T05:22:23.793802Z","iopub.execute_input":"2022-01-07T05:22:23.794081Z","iopub.status.idle":"2022-01-07T05:22:23.799878Z","shell.execute_reply.started":"2022-01-07T05:22:23.794048Z","shell.execute_reply":"2022-01-07T05:22:23.799359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_x = np.transpose(predict_x)[0]\npredict_x.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-07T05:22:29.810034Z","iopub.execute_input":"2022-01-07T05:22:29.811004Z","iopub.status.idle":"2022-01-07T05:22:29.816544Z","shell.execute_reply.started":"2022-01-07T05:22:29.810952Z","shell.execute_reply":"2022-01-07T05:22:29.815863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = list(map(lambda x: 0 if x<=0.5 else 1, predict_x))","metadata":{"execution":{"iopub.status.busy":"2022-01-07T05:22:30.109843Z","iopub.execute_input":"2022-01-07T05:22:30.110487Z","iopub.status.idle":"2022-01-07T05:22:30.122322Z","shell.execute_reply.started":"2022-01-07T05:22:30.110441Z","shell.execute_reply":"2022-01-07T05:22:30.121397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(Y_test, Y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T05:22:30.349122Z","iopub.execute_input":"2022-01-07T05:22:30.350112Z","iopub.status.idle":"2022-01-07T05:22:30.362891Z","shell.execute_reply.started":"2022-01-07T05:22:30.35005Z","shell.execute_reply":"2022-01-07T05:22:30.362021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(Y_test, Y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T05:22:30.499714Z","iopub.execute_input":"2022-01-07T05:22:30.50037Z","iopub.status.idle":"2022-01-07T05:22:30.509141Z","shell.execute_reply.started":"2022-01-07T05:22:30.500293Z","shell.execute_reply":"2022-01-07T05:22:30.508244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}